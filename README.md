# moons_dataset_classification
## Introduction
Machine Learning, a subset of Artificial Intelligence, enables machines to learn autonomously from data (Brown 2021). Arthur Samuel (1959) defines Machine Learning as the field of study that gives computers the “ability to learn without being explicitly programmed” (Géron 2022 pp. 4).  Machine Learning algorithms encompass various approaches such as supervised, unsupervised, self-supervised, semi-supervised and other learning methods. 

This report focuses specifically on supervised machine learning algorithms due to their utilisation of labelled datasets for accurate instance classification (Géron 2022 pp. 10). A comparative analysis of performance metrics for Support Vector Machine (SVM) and Logistic Regression against the Moons dataset from scikit-learn will be evaluated, along with recommendations for the most suitable algorithm for the dataset.

Logistic regression, also known as logit regression, predicts binary class probabilities (Kanade 2022), offering advantages in ease of use, interpretability, and efficiency on the Moons dataset (Jain 2020). However, its linear assumption may limit real-world applicability (Jain 2020). SVM adeptly addresses complex tasks by establishing non-linear boundaries between data points (Kanade 2022) showcasing robustness against noise and strong generalisation for effective classification (Kanade 2022).
Difference in performance algorithms

Accuracy (appendix 1) is one of the simplest metrics to use when comparing the results of a model as it is defined as the number of correct predictions, divided by the total number of predictions (Bajaj 2023). The preliminary Accuracy results presented SVM as the better model with an accuracy score of 93% whereas, the Logistics Regression model underperformed in comparison with an accuracy score of 83%. Whilst the Accuracy metric is great as a starting point in understanding the model’s overall performance, it is too simplistic to of a tool to provide further evaluations and thus conclusions on the model’s overall performance, especially for comparison (Norouzi 2023).

Mean Square Error (MSE) (appendix 2) is used to check the algorithm error rate by finding the average of the squared difference between the target value and the predicted value (Bajaj 2023). As both the Logistic Regression and SVM algorithms were trained against the Moons dataset, the algorithm with the lowest MSE indicated the model’s predictions are closer to the true values, therefore reflecting overall better performance. Similar to Accuracy, SVM outperformed Logistics regression, with an MSE of 0.075 whereas Logistics Regression MSE was slightly higher at 0.1315.

Precision (appendix 3) assesses the proportion of correctly identified positives among all predicted positives. A precision score close to 1 indicates the model accurately distinguishes between correct and incorrect classifications, capturing nearly all true positives. Conversely, a precision score below 0.5 suggests a high incidence of false positives, often attributable to imbalanced classes or insufficiently tuned model hyperparameters (Baja 2023). As with the previous performance metrics, SVM outperforms with a precision of 0.92 therefore instilling the confidence that the model can correctly classify the instances. However, Logistics Regression falls short, with the precision of 0.87.

## Parameter Tuning
The dataset is divided into training and testing sets using ‘train test split’, allocating 80% for training and 20% for testing. This split ensures robust evaluation on unseen data and maintains reproducibility through a set random seed. Preprocessing steps, including feature standardisation via ‘StandardScaler’, ensure uniform scaling, vital for algorithms sensitive to feature scales like SVMs and Logistic Regression. Parameters for classifiers are tailored to dataset characteristics and the task at hand, addressing the terminology of parameter tuning. Cross-validation techniques validate model robustness by iteratively partitioning data into training and validation subsets. These procedures yield reliable estimates of performance metrics, aiding in informed algorithm selection.

## Precision vs Recall performance Compared to ROC Curve
The Receiver Operating Characteristic Curve (ROC) visually depicts a classification model's performance across various thresholds, showcasing the trade-off between sensitivity (true positive rate) and specificity (false positive rate) (Chan no date). The Area Under the Curve (AUC) quantifies the model's capacity to differentiate between classes, with a higher AUC indicating better class separability (Narkhede 2018). The SVM model achieved an AUC of 0.97, surpassing the Logistic Regression model's 0.93. This suggests both models perform well, yet the SVM model exhibits a higher true positive rate, underscoring its superior ability to accurately identify positive instances.

Precision Recall metrics both measures the accuracy of predictions made by the model. However, there are different aspects highlighted in the respective metrics. Whilst precision focuses on the percentage of predictions made by the model that are correct (Gad 2020). Recall (appendix 4) is the same as sensitivity as it measures the percentage of relevant data points that were correctly identified by the model (Brownlee 2023). A good Precision-Recall curve reflects a model's ability to make accurate and reliable predictions on positive instances while minimising false positives. Both the SVM and Logistic Regression model have a high AUC PR thus indicating good model performance, with higher precision achieved across various levels of recall (Steen 2020). However, the SVM model surpasses the Logistic Regression model with an AUC of 0.97 versus the Logistic Regression model at 0.93.

The F1 score (appendix 5), is an evaluation metric combining precision and recall using their harmonic mean, seeks to optimise both aspects simultaneously. Notably, as it represents an average of Precision and Recall, comparing the F1 scores of the SVM model at 0.78 and Logistic Regression at 0.85 reveals that the latter achieves a higher balance between precision and recall. However, it's worth noting that some may argue that an F1 score > 0.9 is considered 'Very Good' (Allwright 2022) (appendix 6), indicating that the F1 scores for both models could be deemed subpar.

## Conclusion
While Logistic Regression demonstrates advantages in ease of use and efficiency, its linear assumption may limit real-world applicability. Conversely, SVM excels in establishing non-linear boundaries, showcasing robustness against noise and strong generalisation. Evaluation metrics including Accuracy, MSE, Precision, Recall and ROC AUC score highlight SVM's superior performance across most measures. Although Logistic Regression achieves a higher balance between Precision and Recall, its overall performance falls short compared to SVM. Thus, while both models exhibit strengths, the SVM model emerges as the more favourable choice for the Moons dataset, despite its slightly lower F1 score.
